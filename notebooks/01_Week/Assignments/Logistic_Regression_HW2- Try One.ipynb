{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB4ruSrXUn31"
   },
   "source": [
    "## Task: Train a logistic regression classifier to predict survival of passengers in titanic dataset\n",
    "\n",
    "You are provided with code to download and load titanic dataset in the form of a csv\n",
    "\n",
    "In the dataset, each row represents information about the passengers of titanic, Like their name, gender, class etc(See the dataframe below for more info).\n",
    "\n",
    "The target column is 'Survived' which tells us whether this particular passenger sirvived or not\n",
    "\n",
    "Use any of all the other columns as the input features (You can choose to drop the columns you see are not worth keeping).\n",
    "\n",
    "Your task is to train a logistic regression model which takes the input featues (make sure to not accidentaly feed the 'Survived' column to the model as input) and predicts the whether a passenger with these features would survive or not.\n",
    "\n",
    "Make sure to put emphasis on code quality and to include a way to judge how good your model is performing on **un-seen data (untrained data)**.\n",
    "\n",
    "As a bonus, see if you can figure out which feature is most likely to affect the survivability of a passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "neIi6I4jQirE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuEIiUJ5T7rv"
   },
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install gdown\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1898,
     "status": "ok",
     "timestamp": 1719257226064,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "YakCDricUDWB",
    "outputId": "b019ae5d-c5d9-476e-8d23-adab3be464f8"
   },
   "outputs": [],
   "source": [
    "!gdown 18YfCgT3Rk7uYWrUzgjb2UR3Nyo9Z68bK  # Download the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1719257229264,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "nGcCgFzwUPGg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1719257229264,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "0qgHG5Y5T4ZE"
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1719257230517,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "dyq-uZYSUQuy",
    "outputId": "b5c250dd-ed9a-4925-fe7f-a7d4df1ec2cc"
   },
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1719257231652,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "56fZMsZuUUba"
   },
   "outputs": [],
   "source": [
    "data = titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1719257232546,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "TNZxOHC-UlwC",
    "outputId": "537ca33a-0803-4b59-9b12-f289e3bd29da"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3fAsrerW_di"
   },
   "source": [
    "# Solving it with SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Understand the data\n",
    "\n",
    "unique_values = set(data[\"Embarked\"])\n",
    "print(\"Unique values of embarked column: \", unique_values)\n",
    "\n",
    "print(\"\\nembarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton\")\n",
    "print(\"nan for not recorded\")\n",
    "\n",
    "print(\"\\nSibSp – Number of siblings and spouses on board\")\n",
    "print(\"Parch – Number of parents and children on board\")\n",
    "\n",
    "print(\"\\nDimensions of the features: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 – Drop columns by intuition\n",
    "\n",
    "data = data.drop(columns=[\"Name\", # just the name, no strings attatched to it\n",
    "                          \"Ticket\", # number / name of ticket does not change outcome\n",
    "                          \"Embarked\", # port of boarding does not count (\"most likely rooms were booked before\")\n",
    "                          \"Fare\", # because it is just a duplicate of passenger class (but would be more accurate, since some first class rooms were more expensive then others for example)\n",
    "                          \"PassengerId\", # because this is not related to the survivablility (also dataframe index is equal)\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 – Check for data completeness\n",
    "\n",
    "nan_count = data[\"Pclass\"].isnull().sum()\n",
    "print(\"Number of NaN values in pclass:\", nan_count)\n",
    "\n",
    "nan_count = data[\"Age\"].isnull().sum()\n",
    "print(\"Number of NaN values in age:\", nan_count)\n",
    "\n",
    "nan_count = data[\"Sex\"].isnull().sum()\n",
    "print(\"Number of NaN values in sex:\", nan_count)\n",
    "\n",
    "nan_count = data[\"SibSp\"].isnull().sum()\n",
    "print(\"Number of NaN values in SipSp:\", nan_count)\n",
    "\n",
    "nan_count = data[\"Parch\"].isnull().sum()\n",
    "print(\"Number of NaN values in parch:\", nan_count)\n",
    "\n",
    "nan_count = data[\"Cabin\"].isnull().sum()\n",
    "print(\"Number of NaN values in cabin:\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 – Drop columns because of too many missing values\n",
    "\n",
    "data = data.drop(columns=[\"Cabin\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - Remove entries with missing ages\n",
    "\n",
    "print(\"Shape before:\", data.shape)\n",
    "\n",
    "# Remove entries where \"age\" is missing\n",
    "data = data.dropna(subset=[\"Age\"])\n",
    "\n",
    "print(\"Shape after: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 – Split data into feature  matrix (X) and target (y)\n",
    "\n",
    "X = data.drop(columns=['Survived'])\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 – Convert categorical columns to numeric (One Hot Encoding)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Sex'], drop_first=True)\n",
    "X = pd.get_dummies(X, columns=['Pclass'], drop_first=True)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 – Normalize features\n",
    "X = X.apply(lambda x: (x-x.min())/(x.max()-x.min()))\n",
    " \n",
    "\n",
    "# Sanity check if date was added\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 – Add intercept term \n",
    "\n",
    "ones = np.ones((X.shape[0], 1))\n",
    "X[\"Intercept\"] = ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 - Create subset for training and seperate test data later\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7331)\n",
    "\n",
    "print(\"Train dataset shape: \", X_train.shape)\n",
    "print(\"Test dataset shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 – Create and train the logistic regression model\n",
    "\n",
    "model = LogisticRegression(verbose=1, max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 – Use the trained model on seperate test data\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 – Print evaluation metrics\n",
    "\n",
    "labels = [\"Died\", \"Survived\"]\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 – Visualize model coefs\n",
    "\n",
    "feature_coef = pd.Series(model.coef_[0], index=X.columns).sort_values(ascending=True)\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot horizontal bar plot\n",
    "plt.barh(feature_coef.index, feature_coef.values, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Visualization')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation: Most important survivability feature\n",
    "###  The biggest influence on if you survive or not is the gender. This is represented with the worsed odds when looking at the above coefs visualization for sex being male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 - Correctly / Acutal Value Visualization\n",
    "\n",
    "# Create the Plotly scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Scatter plot for actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x= np.arange(len(y_test)),\n",
    "    y=y_test,\n",
    "    mode='markers',\n",
    "    name='Actual Values',\n",
    "    marker=dict(color='blue', opacity=0.5, size=12),\n",
    "    hovertemplate='Index: %{x}<br>Actual: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Scatter plot for predicted values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_test)),\n",
    "    y=y_pred,\n",
    "    mode='markers',\n",
    "    name='Predicted Values',\n",
    "    marker=dict(color='red', opacity=0.5, size=8),\n",
    "    hovertemplate='Index: %{x}<br>Predicted: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Add labels and title\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Values',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Value',\n",
    "    legend_title='Legend',\n",
    "\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 - Confusion Matrix Visualization\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cax = ax.matshow(cm, cmap='Blues')\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Add labels, title and axes ticks\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Add labels to each cell in the matrix\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, f'{val}', ha='center', va='center') \n",
    "\n",
    "# Set the tick labels\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_xticklabels(['Not Survived', 'Survived'])\n",
    "ax.set_yticklabels(['Not Survived', 'Survived'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17 – Sanity check to see if correctly predicted and test data is the same as in the confusion matrix\n",
    "\n",
    "matching_survival_count = np.sum((y_test == 1) & (y_pred == 1))\n",
    "print(f\"Number of correct survival predictions: {matching_survival_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing it on my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 – Define needed funtcions for own implementation\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def get_loss(yhat, y):\n",
    "    return np.mean(- y * np.log(yhat) - (1 - y) * np.log(1 - yhat))\n",
    "    \n",
    "def log_reg_gradient_descent(X,y, learning_rate, n_iterations):\n",
    "    # Randomize theta as a starting value\n",
    "    theta = np.random.randn(X.shape[1],1)\n",
    "    # list of losses to keep track of it\n",
    "    ls = []\n",
    "    \n",
    "    # Loop which handles the iterations\n",
    "    for i in range(num_epochs):\n",
    "        #forward pass\n",
    "        z = X @ theta\n",
    "        yhat = sigmoid(z)\n",
    "        l = get_loss(yhat, y)\n",
    "\n",
    "        #backward pass\n",
    "        dtheta = X.T @ (yhat - y)\n",
    "\n",
    "\n",
    "        #optimization\n",
    "        theta = theta - lr * dtheta \n",
    "        \n",
    "        ls.append(l[0]) # only return first value, others are NaN - do not understand why they even exist\n",
    "    return (theta[0], ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 – Create and train own model\n",
    "\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "t, loss_history = log_reg_gradient_descent(X_train, y_train, lr, num_epochs)\n",
    "\n",
    "\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 – Predict with new values\n",
    "\n",
    "def predict(X_new, theta):\n",
    "    z = X_new @ theta\n",
    "    return sigmoid(z)\n",
    "\n",
    "y_pred = predict(X_test, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 – Visualize model coefs\n",
    "\n",
    "feature_coef= t\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot horizontal bar plot\n",
    "plt.barh(t.index, t.values, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Visualization')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 - Correctly / Acutal Value Visualization\n",
    "\n",
    "# Create the Plotly scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Scatter plot for actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x= np.arange(len(y_test)),\n",
    "    y=y_test,\n",
    "    mode='markers',\n",
    "    name='Actual Values',\n",
    "    marker=dict(color='blue', opacity=0.5, size=12),\n",
    "    hovertemplate='Index: %{x}<br>Actual: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Scatter plot for predicted values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred)),\n",
    "    y=y_pred,\n",
    "    mode='markers',\n",
    "    name='Predicted Values',\n",
    "    marker=dict(color='red', opacity=0.5, size=8),\n",
    "    hovertemplate='Index: %{x}<br>Predicted: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Add labels and title\n",
    "fig.update_layout(\n",
    "    title='Actual vs Predicted Values',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Value',\n",
    "    legend_title='Legend',\n",
    "\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
