{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEJ_E7ZGkSRa"
   },
   "source": [
    "## Task: Predict weekly sales of a walmart store using linear regression\n",
    "\n",
    "You are provided with a dataset about Walmart's sales in a CSV file.\n",
    "\n",
    "This is the historical data that covers sales from 2010-02-05 to 2012-11-01, in the file Walmart_Store_sales. Within this file you will find the following fields:\n",
    "\n",
    "1. Store - the store number\n",
    "2. Date - the week of sales\n",
    "3. Weekly_Sales - sales for the given store\n",
    "4. Holiday_Flag - whether the week is a special holiday week: 1 – Holiday week 0 – Non-holiday week\n",
    "5. Temperature - Temperature on the day of sale\n",
    "6. Fuel_Price - Cost of fuel in the region\n",
    "7. CPI – Prevailing consumer price index\n",
    "8. Unemployment - Prevailing unemployment rate\n",
    "\n",
    "Note:\n",
    "\n",
    "You might find it helpful to include information about the kind of holiday week it is. This is something you'll need to add through data processing.\n",
    "You can use this information about the holiday weeks.\n",
    "\n",
    "Holiday Events:\n",
    "1. Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n",
    "2. Labour Day: 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n",
    "3. Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n",
    "4. Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6OEytiztiCi"
   },
   "source": [
    "### Tasks:\n",
    "- Preprocess the data:\n",
    "    - Remove any column which might not be useful\n",
    "    - Add holiday type information\n",
    "    - Normalize the data\n",
    "- Split the data randomly into training and testing sets (80:20 split)\n",
    "- Build and train a linear regression model. You can use any framerwork for this (numpy, sklearn or pytorch)\n",
    "- Evaluate the trained model on test data. Report Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\n",
    "- Visualize model performance using graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uAMaDaamBP6"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhGxkHdlmEiI"
   },
   "outputs": [],
   "source": [
    "# Incase you run this notebook outside colab (where the libraries aren't already pre-installed)\n",
    "\n",
    "%pip install gdown==4.5\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1835,
     "status": "ok",
     "timestamp": 1719415085370,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "QlS3O4RzjKcw",
    "outputId": "e8f37698-76d0-4096-f81b-3412604cf1e5"
   },
   "outputs": [],
   "source": [
    "# Download the CSV file.\n",
    "!gdown 1UjuHkxE8VSQOdklibKqZ72qodJLBynEv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1719415085834,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "-LKzVz90jUup"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1719415085834,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "l93SJ7Mcjmhx"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('Walmart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1719415085834,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "utr4g9CzjrC0",
    "outputId": "f714356c-7779-453c-f928-426d959e14ed"
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1719415088801,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "3rvUQNqPjsIS"
   },
   "outputs": [],
   "source": [
    "data_y = data_df['Weekly_Sales'] # target\n",
    "data_x = data_df.drop(['Weekly_Sales'], axis=1) # input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1719415092536,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "ORfTUDrdkJQm",
    "outputId": "2f15f9ba-88f7-4e6c-bd87-664f44229f4e"
   },
   "outputs": [],
   "source": [
    "data_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1719415109509,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "uh2yhXfZkN3T",
    "outputId": "fd72bac8-6da5-4c71-f297-63d214d005e8"
   },
   "outputs": [],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1719415330506,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "BbJJSFiXI4Wy",
    "outputId": "130d7f0c-5c60-4ae5-ad68-2162b0921cfe"
   },
   "outputs": [],
   "source": [
    "desc = data_x.describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1719415482762,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "k4YWyzPyIdJU"
   },
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "own_df= data_x[[\"Store\", \"Holiday_Flag\", \"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\"]].apply(lambda x: (x-x.min())/(x.max()-x.min()))\n",
    "\n",
    "own_df[\"Date\"] = data_df[\"Date\"]\n",
    "\n",
    "# Sanity check if date was added\n",
    "#print(own_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1719415694750,
     "user": {
      "displayName": "Muhammad Mubashar",
      "userId": "14515435323579848862"
     },
     "user_tz": -60
    },
    "id": "CAA_MLAgJtmD"
   },
   "outputs": [],
   "source": [
    "y=data_y\n",
    "y_max = np.max(y)\n",
    "y_min = np.min(y)\n",
    "y = (y-y_min)/(y_max-y_min)\n",
    "\n",
    "# Sanity check\n",
    "print(min(y), max(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing it on my own (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 – Remove columns that are not of interest\n",
    "#     A: I would remove the store column, since we want to predict overall sales of walmart and not drill down for specific loactions\n",
    "\n",
    "own_df = own_df.drop(\"Store\", axis=1, inplace=False) # axis=1 => delete column, inplace=false => not edit on original data\n",
    "\n",
    "print(own_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 – Add holiday information\n",
    "\n",
    "# Check for data type\n",
    "print(\"Data-Type before casting: \", type(own_df[\"Date\"].loc[0])) \n",
    "\n",
    "# Cast to right datetime format instead of string\n",
    "own_df[\"Date\"] = pd.to_datetime(own_df[\"Date\"], format=\"%d-%m-%Y\")\n",
    "\n",
    "# Sanity check\n",
    "print(\"Data-Type after casting: \", type(own_df[\"Date\"].loc[0])) \n",
    "\n",
    "# Dictionary of holiday dates and types\n",
    "holiday_dates = {\n",
    "    \"2010-02-12\": \"Super Bowl\",\n",
    "    \"2011-02-11\": \"Super Bowl\",\n",
    "    \"2012-02-10\": \"Super Bowl\",\n",
    "    \"2010-09-10\": \"Labor Day\",\n",
    "    \"2011-09-09\": \"Labor Day\",\n",
    "    \"2012-09-07\": \"Labor Day\",\n",
    "    \"2010-11-26\": \"Thanksgiving\",\n",
    "    \"2011-11-25\": \"Thanksgiving\",\n",
    "    \"2012-11-23\": \"Thanksgiving\",\n",
    "    \"2010-12-31\": \"Christmas\",\n",
    "    \"2011-12-30\": \"Christmas\",\n",
    "    \"2012-12-28\": \"Christmas\"\n",
    "}\n",
    "\n",
    "# Add a new column \"Holiday_Type\" to the DataFrame\n",
    "own_df[\"Holiday_Type\"] = own_df[\"Date\"].apply(lambda x: holiday_dates.get(x.strftime(\"%Y-%m-%d\"), \"None\"))\n",
    "\n",
    "# Check if holidays get assigned\n",
    "#print(set(own_df[\"Holiday_Type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 – One-hot encode \"Holiday_Type\"\n",
    "\n",
    "# => adds new columns for every holiday and sets the respective entry to 1 if holiday applies other option is 0\n",
    "own_df = pd.get_dummies(own_df, columns=['Holiday_Type'], drop_first=True)\n",
    "\n",
    "own_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 – Split train and test data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Create feature matrix, but without \"Weekly Sales\" (since it is the target) and Date since it is not relevant.\n",
    "X = own_df.drop(columns=[\"Date\"])\n",
    "\n",
    "# Create target variable vector (just assign the one from above for sanity)\n",
    "y = y\n",
    "\n",
    "# random_state is seed to have reproducibility \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)\n",
    "\n",
    "# Sanity check to see distribution\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 – Build regression model\n",
    "\n",
    "# Add a column of ones to X_train and X_test for the intercept term (bias or called c in normal mx-function) \n",
    "#  This step also casts dataframe to numpy array\n",
    "ones_train = np.ones((X_train.shape[0], 1))\n",
    "X_train = np.concatenate([ones_train, X_train], axis=1)\n",
    "\n",
    "ones_test = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.concatenate([ones_test, X_test], axis=1)\n",
    "\n",
    "\n",
    "# Additionally reshape targets to ensure correct dimensions for the matrix operations (multiplication)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 – Train the model, using the normal equation\n",
    "\n",
    "theta = np.linalg.inv(X_train.T @ X_train) @ (X_train.T @ y_train)\n",
    "\n",
    "print(theta.shape)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 – Predict targets with trained model with test data\n",
    "\n",
    "# Predict\n",
    "y_pred = X_test @ theta\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_own = np.mean(np.abs(y_pred - y_test.flatten()))\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_own = np.mean((y_pred - y_test) ** 2)\n",
    "\n",
    "# Print MAE and MSE\n",
    "print(\"Own model MAE: \", mae_own)\n",
    "print(\"Own model MSE: \", mse_own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals_own = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot using Plotly\n",
    "fig = make_subplots()\n",
    "\n",
    "# Add trace for actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_test)),\n",
    "    y=y_test.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue'),\n",
    "    name='Actual Values',\n",
    "    hovertemplate='Index: %{x}<br>Actual Sales: %{y}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Add trace for predicted values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred)),\n",
    "    y=y_pred.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='red'),\n",
    "    name='Predicted Values – Own Method',\n",
    "    hovertemplate='Index: %{x}<br>Predicted Sales: %{y}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Actual vs. Predicted Weekly Sales',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Weekly Sales',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do the sales number look so wierd?\n",
    "\n",
    "### Because the sales prediction model got normalized input data. Therefor it adapted to the normalized numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scatter plot for residuals\n",
    "fig_residuals = go.Figure()\n",
    "\n",
    "# Add trace for residuals of custom model\n",
    "fig_residuals.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred)),\n",
    "    y=residuals_own.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue'),\n",
    "    name='Residuals (Custom Model)',\n",
    "    hovertemplate='Index: %{x}<br>Residual: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig_residuals.update_layout(\n",
    "    title='Residuals Plot',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Residuals',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig_residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Distribution of Residuals Plot\n",
    "fig_dist_residuals = go.Figure()\n",
    "\n",
    "# Add histogram for residuals\n",
    "fig_dist_residuals.add_trace(go.Histogram(\n",
    "    x=residuals_own.flatten(),\n",
    "    nbinsx=30,\n",
    "    marker=dict(color='blue'),\n",
    "    name='Residuals Distribution',\n",
    "    hovertemplate='Residuals: %{x}<br>Frequency: %{y}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig_dist_residuals.update_layout(\n",
    "    title='Distribution of Residuals',\n",
    "    xaxis_title='Residuals',\n",
    "    yaxis_title='Frequency',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig_dist_residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving it with SK-LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LhyEPjlIv5U"
   },
   "outputs": [],
   "source": [
    "# Train a model using sklearn -> LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_sklearn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for sklearn try\n",
    "residuals_sklearn = y_test - y_pred_sklearn\n",
    "\n",
    "# Calculate mae, mse for sklearn try\n",
    "mae_sklearn = np.mean(np.abs(residuals_sklearn))\n",
    "mse_sklearn = np.mean(residuals_sklearn ** 2)\n",
    "\n",
    "#print(mae_sklearn)\n",
    "#print(mse_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE own method\", mae_own)\n",
    "print(\"MSE own method\", mse_own)\n",
    "print(\"----\")\n",
    "print(\"MAE sklearn method\", mae_sklearn)\n",
    "print(\"MSE slearn method\", mse_sklearn)\n",
    "\n",
    "print(\"\\nInterpretation: \\n\")\n",
    "print(\"Lower MAE means that, on average,the model's predictions are closer to the actual values.\\n\")\n",
    "print(\"Lower MSE indicates that the model has fewer large errors, which is to consider if you have a dataset with many outliers. These outliers than dont have such a big impact\")\n",
    "\n",
    "print(\"\\n-> sklearn model is preferable since it has a lower mae as well as mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot using Plotly\n",
    "fig = make_subplots()\n",
    "\n",
    "# Add trace for actual values\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_test)),\n",
    "    y=y_test.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue'),\n",
    "    name='Actual Values',\n",
    "    hovertemplate='Index: %{x}<br>Actual Sales: %{y}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Add trace for predicted values (own method)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred)),\n",
    "    y=y_pred.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='red'),\n",
    "    name='Predicted Values – Own Method',\n",
    "    hovertemplate='Index: %{x}<br>Predicted Sales: %{y}<extra></extra>'\n",
    "))\n",
    "\n",
    "\n",
    "# Add trace for predicted values (sklearn method)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred_sklearn)),\n",
    "    y=y_pred_sklearn.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='green'),\n",
    "    name='Predicted Values – sklearn',\n",
    "    hovertemplate='Index: %{x}<br>Predicted Sales: %{y}<extra></extra>'\n",
    "))\n",
    "\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Actual vs. Predicted Weekly Sales',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Weekly Sales',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scatter plot for residuals\n",
    "fig_residuals = go.Figure()\n",
    "\n",
    "# Add trace for residuals of custom model\n",
    "fig_residuals.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred)),\n",
    "    y=residuals_own.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue'),\n",
    "    name='Residuals (Custom Model)',\n",
    "    hovertemplate='Index: %{x}<br>Residual: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Add trace for residuals of sklearn model\n",
    "fig_residuals.add_trace(go.Scatter(\n",
    "    x=np.arange(len(y_pred)),\n",
    "    y=residuals_sklearn.flatten(),\n",
    "    mode='markers',\n",
    "    marker=dict(color='red'),\n",
    "    name='Residuals (Sklearn Model)',\n",
    "    hovertemplate='Index: %{x}<br>Residual: %{y}<extra></extra>',\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "\n",
    "# Update layout\n",
    "fig_residuals.update_layout(\n",
    "    title='Residuals Plot',\n",
    "    xaxis_title='Index',\n",
    "    yaxis_title='Residuals',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig_residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print results\n",
    "print(f\"Coefficients (theta values): \\n{coefficients.reshape(-1,1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
