{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VZmzSrgpUmP"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and set which device type is available\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q25JNpF0pamZ",
        "outputId": "609d1db1-4710-4290-fe24-1727f4400c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1w2zPSfyAoSopS-BhFurKayYa_OhjI9YH\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUMoywQLpcVY",
        "outputId": "3f82ed6e-74b8-4849-b2d8-ad4443ce67d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1w2zPSfyAoSopS-BhFurKayYa_OhjI9YH\n",
            "From (redirected): https://drive.google.com/uc?id=1w2zPSfyAoSopS-BhFurKayYa_OhjI9YH&confirm=t&uuid=8b629e25-8eb5-44cb-851e-1f27aeca0141\n",
            "To: /content/MVSA-Single.zip\n",
            "100% 211M/211M [00:02<00:00, 91.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip MVSA-Single.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "PqzBt2gRpeYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"MVSA_Single/labelResultAll.csv\")\n",
        "\n",
        "# Initialize and fit the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['label_encoded'] = label_encoder.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "BEdITnhbph-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Captions\n",
        "\n",
        "path_to_data = \"MVSA_Single/data/\"\n",
        "# List to store contents of all txt files\n",
        "all_captions = []\n",
        "\n",
        "# List all files in the directory\n",
        "for file in os.listdir(path_to_data):\n",
        "  if file.endswith(\".txt\"):\n",
        "    # Get the full path of the file\n",
        "    file_path = os.path.join(path_to_data, file)\n",
        "\n",
        "    # Open the file and read its content\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "      content = f.read()\n",
        "\n",
        "      # Append the content to the list\n",
        "      all_captions.append(content)\n",
        "df[\"captions\"] = pd.DataFrame({\"captions\": all_captions})"
      ],
      "metadata": {
        "id": "LTdX-1iapkS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MUt8ocy7qh31",
        "outputId": "24f734c7-6dcf-48bd-c990-946e9a5bd701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID     label  label_encoded  \\\n",
              "0   1  positive              2   \n",
              "1   2  positive              2   \n",
              "2   3  positive              2   \n",
              "3   4  positive              2   \n",
              "4   5  positive              2   \n",
              "\n",
              "                                            captions  \n",
              "0  Why don't dolphins fight back when their survi...  \n",
              "1  RT @DogRescue2014: ? Foster urgently needed in...  \n",
              "2   Happy Valentines day Ajit???????khush rehna?? \\n  \n",
              "3                                      https://t��\\n  \n",
              "4  RT @LoveStoneArts: Evil Eye Earrings Lampwork ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62f4f7f8-f9f1-4dbc-aa2a-536da3efa7e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "      <th>label_encoded</th>\n",
              "      <th>captions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>Why don't dolphins fight back when their survi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>RT @DogRescue2014: ? Foster urgently needed in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>Happy Valentines day Ajit???????khush rehna?? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>https://t��\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "      <td>RT @LoveStoneArts: Evil Eye Earrings Lampwork ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62f4f7f8-f9f1-4dbc-aa2a-536da3efa7e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62f4f7f8-f9f1-4dbc-aa2a-536da3efa7e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62f4f7f8-f9f1-4dbc-aa2a-536da3efa7e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-985acc0c-16d6-4468-a046-6ac4716e266e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-985acc0c-16d6-4468-a046-6ac4716e266e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-985acc0c-16d6-4468-a046-6ac4716e266e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4869,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1516,\n        \"min\": 1,\n        \"max\": 5129,\n        \"num_unique_values\": 4869,\n        \"samples\": [\n          4122,\n          1102,\n          1150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"captions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4663,\n        \"samples\": [\n          \"RT @MikeyKehoe: Feel the FEAR see HUSH @HollywoodSFF 2/22 4pm @PromoteHorror @madhouse_ent @IndieFilmTweets @IFIFFest @AlconEnt #fear http:\\ufffd\\ufffd \\n\",\n          \"? #quote #quotes #worthless #tired #ugly #upset #pain #ana #alone #anxiety #anorexia #anore\\ufffd\\ufffd \\n\",\n          \"RT @dpradhanbjp: Feel elated to be part of #RathYatra of Mahaprabhu Sri Jagannath in the #Nabakalebara Year in religious city Puri. http://\\ufffd\\ufffd\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length df: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gmTYpHKro3W",
        "outputId": "91a378ab-3458-4283-9ad3-bfb0c58822e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length df: 4869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts().plot(kind=\"bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "wAJBRr9Vqogz",
        "outputId": "fa8c062a-bbfe-4625-da27-aa46b0532280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='label'>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## retain only text that contain less that 70 tokens to avoid too much padding\n",
        "df[\"token_size\"] = df[\"captions\"].apply(lambda x: len(x.split(' ')))\n",
        "df = df.loc[df['token_size'] < 70].copy()\n",
        "\n",
        "print(f\"Length after tokenizaton and limit on 70: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RevFtTxZqvv6",
        "outputId": "b8b814a3-f7ee-4e9e-c775-54fa9bc30227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length after tokenizaton and limit on 70: 4869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Vocabulary\n",
        "\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "\n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "\n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "\n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "metadata": {
        "id": "N90-gR-jrh2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## construct vocab and indexing\n",
        "inputs = ConstructVocab(df[\"captions\"].values.tolist())\n",
        "\n",
        "## examples of what is in the vocab\n",
        "inputs.vocab[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvkXMSk_sQi9",
        "outputId": "68f1a348-38ed-444f-b853-9b2525cdcf13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '\\n',\n",
              " '!',\n",
              " '!!',\n",
              " '!!!',\n",
              " '!!!!',\n",
              " '!!!!!!',\n",
              " '!!/):&3\\'wH!2@\"0hGrw$]+?=_=%-$#_+\\'el',\n",
              " '\"',\n",
              " '\"\"impotent\"\"']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in df[\"captions\"].values.tolist()]"
      ],
      "metadata": {
        "id": "5lEJ7zISsVX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data padding\n",
        "\n",
        "# function to find max length of batch\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)\n",
        "\n",
        "\n",
        "## padding sequences\n",
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT61_shhsjMT",
        "outputId": "de75d0c9-e32f-4ea5-d126-0a73d5c94f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "metadata": {
        "id": "MSGZHmoWs60U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## convert targets to one-hot encoding vectors\n",
        "sentiments = list(set(df.label.unique()))\n",
        "num_sentiments = len(sentiments)\n",
        "\n",
        "## binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(sens) & set(sentiments) for sens in df[['label']].values]\n",
        "bin_sentiments = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_sentiments.tolist())"
      ],
      "metadata": {
        "id": "7XcIqUzrtFwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "TmKPYHHkuEob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "## Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "## Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XUeFl70tSKF",
        "outputId": "5790c52b-44d4-4e11-9e5c-9bd49d42d1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3895, 3895, 487, 487, 487, 487)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader"
      ],
      "metadata": {
        "id": "Q62kAcCuubzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define a few useful parameters\n",
        "\n",
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE"
      ],
      "metadata": {
        "id": "5C2NVrAEuXuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "\n",
        "        return x, y, x_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "jQqS87_eueoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset instance\n",
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "\n",
        "## Data Loader instance\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE,\n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE,\n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE,\n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "metadata": {
        "id": "odZY0ZCiumd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving with GRU"
      ],
      "metadata": {
        "id": "aZIPBkbQvKJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super().__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        ## layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5) # avoid overfitting\n",
        "        self.rnn = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros(1, self.batch_sz, self.hidden_units)\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state().to(x.device)\n",
        "        output, self.hidden = self.rnn(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden"
      ],
      "metadata": {
        "id": "Xf5vBM0HupfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = 3 # num_sentiments"
      ],
      "metadata": {
        "id": "XZHsAHXgvl_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y, prediction):\n",
        "    #CrossEntropyLoss expects outputs and class indices as target\n",
        "    ## convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target)\n",
        "    return loss\n",
        "\n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_QKMkqNZwpOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enabling cuda\n",
        "model = SentGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "# Count the frequencies of each class\n",
        "class_counts = df['label'].value_counts()\n",
        "\n",
        "# Calculate inverse frequencies\n",
        "inverse_frequencies = 1.0 / class_counts\n",
        "\n",
        "# Normalize weights\n",
        "normalized_weights = inverse_frequencies / inverse_frequencies.sum()\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "class_weights = torch.tensor(normalized_weights.values, dtype=torch.float)\n",
        "\n",
        "# Define the loss criterion with weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "## loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "lHmd2i9RvMIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "nkD4rUvIvOwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enabling cuda\n",
        "model = SentGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "## loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "NKbnu5OkwGUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "\n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        inp = inp.permute(1 ,0).to(device)\n",
        "        predictions, _ = model(inp, lens)\n",
        "\n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "\n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens)\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1,\n",
        "                                                             total_loss / TRAIN_N_BATCH,\n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w65cyWJjwZAJ",
        "outputId": "cd515dda-21aa-4b5d-9f3e-bb1731d8d7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3595\n",
            "Epoch 1 Loss 0.3590 -- Train Acc. 52.6823 -- Val Acc. 54.6875\n",
            "Time taken for 1 epoch 1.2013390064239502 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.3359\n",
            "Epoch 2 Loss 0.3383 -- Train Acc. 54.4792 -- Val Acc. 55.8036\n",
            "Time taken for 1 epoch 1.1302413940429688 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.2869\n",
            "Epoch 3 Loss 0.3120 -- Train Acc. 56.6927 -- Val Acc. 49.3304\n",
            "Time taken for 1 epoch 1.1327180862426758 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.2410\n",
            "Epoch 4 Loss 0.2343 -- Train Acc. 70.7552 -- Val Acc. 43.9732\n",
            "Time taken for 1 epoch 1.1700825691223145 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.1640\n",
            "Epoch 5 Loss 0.1317 -- Train Acc. 85.2344 -- Val Acc. 38.3929\n",
            "Time taken for 1 epoch 1.1808934211730957 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TMRm5Fgowdcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying with basic RNN\n",
        "\n",
        "class SentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(SentRNN, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        ## layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5) # avoid overfitting\n",
        "        self.rnn = nn.RNN(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros(1, self.batch_sz, self.hidden_units)\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state().to(x.device)\n",
        "        output, self.hidden = self.rnn(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden"
      ],
      "metadata": {
        "id": "L03goCEZ03rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enabling cuda\n",
        "model = SentRNN(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "## loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "pO6Q6DtZ7-5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "\n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        inp = inp.permute(1 ,0).to(device)\n",
        "        predictions, _ = model(inp, lens)\n",
        "\n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "\n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens)\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1,\n",
        "                                                             total_loss / TRAIN_N_BATCH,\n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX1Jnz0B8COZ",
        "outputId": "064d1c4c-168e-4315-8a0f-00383f091d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3475\n",
            "Epoch 1 Loss 0.3761 -- Train Acc. 48.5156 -- Val Acc. 55.5804\n",
            "Time taken for 1 epoch 0.627025842666626 sec\n",
            "\n",
            "Epoch 2 Batch 0 Val. Loss 0.3155\n",
            "Epoch 2 Loss 0.3544 -- Train Acc. 51.0417 -- Val Acc. 48.8839\n",
            "Time taken for 1 epoch 0.6026344299316406 sec\n",
            "\n",
            "Epoch 3 Batch 0 Val. Loss 0.3676\n",
            "Epoch 3 Loss 0.3518 -- Train Acc. 51.9010 -- Val Acc. 55.8036\n",
            "Time taken for 1 epoch 0.5960578918457031 sec\n",
            "\n",
            "Epoch 4 Batch 0 Val. Loss 0.3399\n",
            "Epoch 4 Loss 0.3514 -- Train Acc. 51.5885 -- Val Acc. 55.3571\n",
            "Time taken for 1 epoch 0.5938575267791748 sec\n",
            "\n",
            "Epoch 5 Batch 0 Val. Loss 0.3654\n",
            "Epoch 5 Loss 0.3541 -- Train Acc. 52.2656 -- Val Acc. 52.0089\n",
            "Time taken for 1 epoch 0.5921895503997803 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying with LSTM\n",
        "\n",
        "class SentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super().__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        ## layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5) # avoid overfitting\n",
        "        self.rnn = nn.LSTM(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return torch.zeros(1, self.batch_sz, self.hidden_units)\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state().to(x.device)\n",
        "        self.cell_state = self.initialize_hidden_state().to(x.device)\n",
        "        output, (self.hidden, self.cell_state) = self.rnn(x, (self.hidden, self.cell_state)) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden"
      ],
      "metadata": {
        "id": "h35oNOma8FM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enabling cuda\n",
        "model = SentLSTM(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "## loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "xn_inmKt8gIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "\n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        inp = inp.permute(1 ,0).to(device)\n",
        "        predictions, _ = model(inp, lens)\n",
        "\n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "\n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):\n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens)\n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1,\n",
        "                                                             total_loss / TRAIN_N_BATCH,\n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4M2Mci18jHk",
        "outputId": "8513ede0-95cd-4ecd-c2e3-6e80524cc580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Val. Loss 0.3461\n",
            "Epoch 1 Loss 0.3419 -- Train Acc. 55.3125 -- Val Acc. 55.8036\n",
            "Epoch 2 Batch 0 Val. Loss 0.3370\n",
            "Epoch 2 Loss 0.3339 -- Train Acc. 55.3125 -- Val Acc. 56.2500\n",
            "Epoch 3 Batch 0 Val. Loss 0.3043\n",
            "Epoch 3 Loss 0.3322 -- Train Acc. 55.4167 -- Val Acc. 56.0268\n",
            "Epoch 4 Batch 0 Val. Loss 0.3311\n",
            "Epoch 4 Loss 0.3331 -- Train Acc. 55.2604 -- Val Acc. 56.4732\n",
            "Epoch 5 Batch 0 Val. Loss 0.3214\n",
            "Epoch 5 Loss 0.3329 -- Train Acc. 55.4948 -- Val Acc. 56.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4W-an68XF8vB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}